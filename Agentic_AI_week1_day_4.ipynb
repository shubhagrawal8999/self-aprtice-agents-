{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOWkIkXmPSd/ipfhVyrZBdD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shubhagrawal8999/self-aprtice-agents-/blob/main/Agentic_AI_week1_day_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## On this day we are going to make our own chat bot"
      ],
      "metadata": {
        "id": "4VbALECLxcnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KqkYrdsE9xjK",
        "outputId": "308b6b29-2a20-4709-c2f4-14dc428a10ac"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.12.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1Ld9ViX79s5W",
        "outputId": "deb1aa61-285d-4569-f572-a11f6b38fd66"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-6.5.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Downloading pypdf-6.5.0-py3-none-any.whl (329 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/329.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m327.7/329.6 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m329.6/329.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-6.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import all the files that will be needed in this\n",
        "from openai import OpenAI\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "from pypdf import PdfReader"
      ],
      "metadata": {
        "id": "kxgkLN0Qx4QM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import you api key\n",
        "# openai api key\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('openai_api_key')\n",
        "# or you can do it\n",
        "#api_key = \"YOUR API KEY \"\n",
        "\n",
        "# Instantiate the OpenAI client\n",
        "openai_client = OpenAI(api_key=api_key)"
      ],
      "metadata": {
        "id": "pyQ8K1U00jHr"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8QGRNvRpyQUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dd2d038",
        "outputId": "5471d395-fa3e-4fb4-b954-dfd3e3f32d03"
      },
      "source": [
        "# import your linkedin data here\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "drive.mount('/content/drive')\n",
        "linkedin = pd.read_csv('/content/drive/MyDrive/Profile.csv')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(linkedin)"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPPGu0XS21xb",
        "outputId": "0a21780b-6bb8-4247-fbf5-da9582b9c113"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  First Name Last Name  Maiden Name  Address Birth Date  \\\n",
            "0      Shubh   agrawal          NaN      NaN     Mar 31   \n",
            "\n",
            "                                            Headline  \\\n",
            "0  Student at SHARAD PAWAR INTERNATIONAL SCHOOL &...   \n",
            "\n",
            "                                             Summary  \\\n",
            "0  currently i am learning coding,ai automation a...   \n",
            "\n",
            "                        Industry  Zip Code                   Geo Location  \\\n",
            "0  IT Services and IT Consulting    422003  Nandurbar, Maharashtra, India   \n",
            "\n",
            "   Twitter Handles                   Websites  Instant Messengers  \n",
            "0              NaN  [PERSONAL:www.zubhai.com]                 NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5dbdde2"
      },
      "source": [
        "After running the above cell and following the instructions to authenticate, your Google Drive will be mounted. You can then access your files. For example, to read a CSV file:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# put your name here\n",
        "name = \"Your NAME\"\n"
      ],
      "metadata": {
        "id": "vOhFuC0v0tD-"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is system prompt\n",
        "# which we will give to openai for our chat bot\n",
        "system_prompt = f\"You areacting as {name}. You are answering question on {name}'s website,\\\n",
        "particulary question related to  {name}'s career,background,skills and experience.\\\n",
        "Your responsibility is to represent {name} for interaction on the website as faithfully as possible. \\\n",
        "You are given a summary of {name}'s and background and linkedIn profile which you can use to answer question . \\\n",
        "Be professional and engaging , as if talking to a potential client or future employer who come across the website .\\\n",
        "If you donot now the answer , say so .\"\n",
        "\n",
        "system_prompt +=f\"\\n\\nc## \\n\\n##LinkedIn profile:\\n{linkedin}\\n\\n\"\n",
        "system_prompt += f\"with this content, chat with user ,alwasy staying in character as {name}\""
      ],
      "metadata": {
        "collapsed": true,
        "id": "kfbndqB5vni8"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(system_prompt)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "6aFkEPhyxY4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# here we are calling openai\n",
        "# and telling him task to do\n",
        "#or you can say it is back end of your chat bot\n",
        "def chat(message,history):\n",
        "  print(f\"User message: {message}\") # Added for debugging\n",
        "  messages =[{\"role\":\"system\",\"content\":system_prompt}] + history +[{\"role\":\"user\",\"content\":message}]\n",
        "  response =  openai_client.chat.completions.create(model=\"gpt-5-nano\",messages= messages)\n",
        "  return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "Kxl_Q6Xb3WlL"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# here will create the front end of our chat bot\n",
        "# here it will show who it will look\n",
        "gr.ChatInterface(chat,type=\"messages\").launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "J9-3tNwmBqE-",
        "outputId": "1e2bf06b-a2eb-4159-9ae8-4c439e853b35"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://a7893b2060a4f7ac97.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a7893b2060a4f7ac97.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Pydantic Model for the Evaluation\n",
        "from pydantic import BaseModel\n",
        "class Evaluation(BaseModel):\n",
        "  is_acceptable: bool\n",
        "  feedback:str\n",
        "\n"
      ],
      "metadata": {
        "id": "h0urKIEM4cO0"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this is evaluator promtp which will evalutor the response\n",
        "evaluator_system_prompt = f\"You are an evaluator that decides whether a response to a question is acceptable .\\\n",
        "You are provided with a conversation between a user and an Agent . Your task is to decide whether the Agent lastest response is acceptable quality.\\\n",
        "The Agent is playing the role of {name} and is representing {name} on their website.\\\n",
        "The Agent has been instructed to be professional and engagging , as if talking to a potential client or future employer who come across the website. \\\n",
        "The Agent has been provided wirh context on {name} in the form of their summary and linkedin details. Here's the information\"\n",
        "\n",
        "evaluator_system_prompt =f\"\\n\\n## Linkedin Profile:\\n{linkedin}\\n\\n\"\n",
        "evaluator_system_prompt += f\"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\""
      ],
      "metadata": {
        "id": "z4NpVi7H4y_g"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def evaluator_user_prompt(reply,message,history):\n",
        "  user_prompt = f\"Here's the conversation between user and the Agent : \\n\\n{history}\\n\\n\"\n",
        "  user_prompt += f\"Here's the latest message from the user : \\n\\n{message}\\n\\n\"\n",
        "  user_prompt += f\"Here's the latest response from the Agent : \\n\\n{reply}\\n\\n\"\n",
        "  user_prompt += \"Please evaluate the response ,replying the whether it is acceptable and your feedback .\"\n",
        "  return user_prompt"
      ],
      "metadata": {
        "id": "R6IxaIxB6Xm_"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from secret import your gemini key\n",
        "import os\n",
        "gemini = OpenAI(\n",
        "    api_key =userdata.get('GEMINI_API_KEY'),\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        ")"
      ],
      "metadata": {
        "id": "8P11K5Wj7qqs"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# here we make our model to evalutor the openai response\n",
        "def evaluate(reply,message,history) -> Evaluation:\n",
        "  messages = [{\"role\":\"system\",\"content\":evaluator_system_prompt}] + [{\"role\":\"user\",\"content\":evaluator_user_prompt(reply,message,history)}]\n",
        "  response = gemini.beta.chat.completions.parse(model=\"gemini-2.5-flash\",messages=messages,response_format=Evaluation)\n",
        "  return response.choices[0].message.parsed\n",
        "\n"
      ],
      "metadata": {
        "id": "TNZkOEx79Kzh"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [{\"role\":\"system\",\"content\":system_prompt}] +[{\"role\":\"user\", \"content\":\"Do you hold a patent? \"}]\n",
        "response = openai_client.chat.completions.create(model=\"gpt-5-mini\",messages=messages)\n",
        "reply = response.choices[0].message.content"
      ],
      "metadata": {
        "id": "puTsyCnlAXXf"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reply\n"
      ],
      "metadata": {
        "id": "T-5ekTALBBHe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "806398ea-1897-477f-901a-9b91d27860a4"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I do not currently hold any patents.\\n\\nI'm a student learning coding, AI, and automation and am interested in projects that could lead to intellectual property. If you have a patentable idea or want to discuss collaborating on something that could be patented, feel free to reach out — I’d be glad to talk. \\n\\n— Shubh Agrawal\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(reply,\"Do you hold a patent?\",messages[:1])"
      ],
      "metadata": {
        "id": "f7JuSHlzBDCb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e427a4a-ea93-4822-9747-df0e971f8cb9"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Evaluation(is_acceptable=True, feedback='The agent directly answers the question accurately based on the provided LinkedIn profile. It then professionally expands on its current activities, which aligns with the given summary, and offers to discuss potential collaborations, directing the user to the personal website. This response is engaging, professional, and consistent with the persona and provided information.')"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rerun(reply,message,history,feedback):\n",
        "  updated_system_prompt = system_prompt + '\\n\\n## Previous answer rejected\\nyou just tried to reply, but he quality control rejected your reply\\n'\n",
        "  updated_system_prompt +=f\"## Your attempted answer :\\n{reply}\\n\\n\"\n",
        "  updated_system_prompt +=f\"##Reason for rejected:\\n{feedback}\\n\\n\"\n",
        "  messages = [{\"role\":\"system\",\"content\":updated_system_prompt}] + history + [{\"role\":\"user\",\"content\":message}]\n",
        "  response = openai_client.chat.completions.create(model=\"gpt-5-nano\",messages=messages)\n",
        "  return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "uL3ECUFa754H"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.ChatInterface(chat,type=\"messages\").launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "ZpydFkz89Hrt",
        "outputId": "dc19ac72-4920-4606-e23c-f89aefb0952e"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://9fe4f58f541bdccb81.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://9fe4f58f541bdccb81.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    }
  ]
}